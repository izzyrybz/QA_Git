[2023-02-08 12:40:05,053] INFO:__main__:number of available cores: 4
[2023-02-08 12:40:05,340] INFO:__main__:==> Epoch 0, Train 	Loss: 0.4255748689174652 	Pearson: 0.10361669212579727	MSE: 0.32719945907592773, 	F1: (0, 0, 0)
[2023-02-08 12:40:05,647] INFO:__main__:==> Epoch 0, Dev 	Loss: 0.2781238257884979 	Pearson: 0.5756545066833496	MSE: 0.1828107237815857, 	F1: (0, 0, 0)
[2023-02-08 12:40:05,648] INFO:__main__:==> Epoch 0, Test 	Loss: 0.3803824484348297 	Pearson: 0.19001586735248566	MSE: 0.28294774889945984, 	F1: (0, 0, 0)
[2023-02-08 12:40:05,894] INFO:__main__:==> Epoch 1, Train 	Loss: 0.4255748689174652 	Pearson: 0.10361669212579727	MSE: 0.32719945907592773, 	F1: (0, 0, 0)
[2023-02-08 12:40:06,277] INFO:__main__:==> Epoch 1, Dev 	Loss: 0.2781238257884979 	Pearson: 0.5756545066833496	MSE: 0.1828107237815857, 	F1: (0, 0, 0)
[2023-02-08 12:40:06,279] INFO:__main__:==> Epoch 1, Test 	Loss: 0.3803824484348297 	Pearson: 0.19001586735248566	MSE: 0.28294774889945984, 	F1: (0, 0, 0)
[2023-02-08 12:40:06,511] INFO:__main__:==> Epoch 2, Train 	Loss: 0.4255748689174652 	Pearson: 0.10361669212579727	MSE: 0.32719945907592773, 	F1: (0, 0, 0)
[2023-02-08 12:40:06,841] INFO:__main__:==> Epoch 2, Dev 	Loss: 0.2781238257884979 	Pearson: 0.5756545066833496	MSE: 0.1828107237815857, 	F1: (0, 0, 0)
[2023-02-08 12:40:06,843] INFO:__main__:==> Epoch 2, Test 	Loss: 0.3803824484348297 	Pearson: 0.19001586735248566	MSE: 0.28294774889945984, 	F1: (0, 0, 0)
[2023-02-08 12:40:07,078] INFO:__main__:==> Epoch 3, Train 	Loss: 0.4255748689174652 	Pearson: 0.10361669212579727	MSE: 0.32719945907592773, 	F1: (0, 0, 0)
[2023-02-08 12:40:07,377] INFO:__main__:==> Epoch 3, Dev 	Loss: 0.2781238257884979 	Pearson: 0.5756545066833496	MSE: 0.1828107237815857, 	F1: (0, 0, 0)
[2023-02-08 12:40:07,380] INFO:__main__:==> Epoch 3, Test 	Loss: 0.3803824484348297 	Pearson: 0.19001586735248566	MSE: 0.28294774889945984, 	F1: (0, 0, 0)
[2023-02-08 12:40:07,618] INFO:__main__:==> Epoch 4, Train 	Loss: 0.4255748689174652 	Pearson: 0.10361669212579727	MSE: 0.32719945907592773, 	F1: (0, 0, 0)
[2023-02-08 12:40:07,910] INFO:__main__:==> Epoch 4, Dev 	Loss: 0.2781238257884979 	Pearson: 0.5756545066833496	MSE: 0.1828107237815857, 	F1: (0, 0, 0)
[2023-02-08 12:40:07,912] INFO:__main__:==> Epoch 4, Test 	Loss: 0.3803824484348297 	Pearson: 0.19001586735248566	MSE: 0.28294774889945984, 	F1: (0, 0, 0)
[2023-02-08 12:40:08,126] INFO:__main__:==> Epoch 5, Train 	Loss: 0.4255748689174652 	Pearson: 0.10361669212579727	MSE: 0.32719945907592773, 	F1: (0, 0, 0)
[2023-02-08 12:40:08,423] INFO:__main__:==> Epoch 5, Dev 	Loss: 0.2781238257884979 	Pearson: 0.5756545066833496	MSE: 0.1828107237815857, 	F1: (0, 0, 0)
[2023-02-08 12:40:08,423] INFO:__main__:==> Epoch 5, Test 	Loss: 0.3803824484348297 	Pearson: 0.19001586735248566	MSE: 0.28294774889945984, 	F1: (0, 0, 0)
[2023-02-08 12:40:08,704] INFO:__main__:==> Epoch 6, Train 	Loss: 0.4255748689174652 	Pearson: 0.10361669212579727	MSE: 0.32719945907592773, 	F1: (0, 0, 0)
[2023-02-08 12:40:08,997] INFO:__main__:==> Epoch 6, Dev 	Loss: 0.2781238257884979 	Pearson: 0.5756545066833496	MSE: 0.1828107237815857, 	F1: (0, 0, 0)
[2023-02-08 12:40:08,998] INFO:__main__:==> Epoch 6, Test 	Loss: 0.3803824484348297 	Pearson: 0.19001586735248566	MSE: 0.28294774889945984, 	F1: (0, 0, 0)
[2023-02-08 12:40:09,251] INFO:__main__:==> Epoch 7, Train 	Loss: 0.4255748689174652 	Pearson: 0.10361669212579727	MSE: 0.32719945907592773, 	F1: (0, 0, 0)
[2023-02-08 12:40:09,587] INFO:__main__:==> Epoch 7, Dev 	Loss: 0.2781238257884979 	Pearson: 0.5756545066833496	MSE: 0.1828107237815857, 	F1: (0, 0, 0)
[2023-02-08 12:40:09,588] INFO:__main__:==> Epoch 7, Test 	Loss: 0.3803824484348297 	Pearson: 0.19001586735248566	MSE: 0.28294774889945984, 	F1: (0, 0, 0)
[2023-02-08 12:40:09,807] INFO:__main__:==> Epoch 8, Train 	Loss: 0.4255748689174652 	Pearson: 0.10361669212579727	MSE: 0.32719945907592773, 	F1: (0, 0, 0)
[2023-02-08 12:40:10,087] INFO:__main__:==> Epoch 8, Dev 	Loss: 0.2781238257884979 	Pearson: 0.5756545066833496	MSE: 0.1828107237815857, 	F1: (0, 0, 0)
[2023-02-08 12:40:10,089] INFO:__main__:==> Epoch 8, Test 	Loss: 0.3803824484348297 	Pearson: 0.19001586735248566	MSE: 0.28294774889945984, 	F1: (0, 0, 0)
[2023-02-08 12:40:10,278] INFO:__main__:==> Epoch 9, Train 	Loss: 0.4255748689174652 	Pearson: 0.10361669212579727	MSE: 0.32719945907592773, 	F1: (0, 0, 0)
[2023-02-08 12:40:10,581] INFO:__main__:==> Epoch 9, Dev 	Loss: 0.2781238257884979 	Pearson: 0.5756545066833496	MSE: 0.1828107237815857, 	F1: (0, 0, 0)
[2023-02-08 12:40:10,583] INFO:__main__:==> Epoch 9, Test 	Loss: 0.3803824484348297 	Pearson: 0.19001586735248566	MSE: 0.28294774889945984, 	F1: (0, 0, 0)
[2023-02-08 12:40:10,787] INFO:__main__:==> Epoch 10, Train 	Loss: 0.4255748689174652 	Pearson: 0.10361669212579727	MSE: 0.32719945907592773, 	F1: (0, 0, 0)
[2023-02-08 12:40:11,052] INFO:__main__:==> Epoch 10, Dev 	Loss: 0.2781238257884979 	Pearson: 0.5756545066833496	MSE: 0.1828107237815857, 	F1: (0, 0, 0)
[2023-02-08 12:40:11,054] INFO:__main__:==> Epoch 10, Test 	Loss: 0.3803824484348297 	Pearson: 0.19001586735248566	MSE: 0.28294774889945984, 	F1: (0, 0, 0)
[2023-02-08 12:40:11,230] INFO:__main__:==> Epoch 11, Train 	Loss: 0.4255748689174652 	Pearson: 0.10361669212579727	MSE: 0.32719945907592773, 	F1: (0, 0, 0)
[2023-02-08 12:40:11,480] INFO:__main__:==> Epoch 11, Dev 	Loss: 0.2781238257884979 	Pearson: 0.5756545066833496	MSE: 0.1828107237815857, 	F1: (0, 0, 0)
[2023-02-08 12:40:11,482] INFO:__main__:==> Epoch 11, Test 	Loss: 0.3803824484348297 	Pearson: 0.19001586735248566	MSE: 0.28294774889945984, 	F1: (0, 0, 0)
[2023-02-08 12:40:11,682] INFO:__main__:==> Epoch 12, Train 	Loss: 0.4255748689174652 	Pearson: 0.10361669212579727	MSE: 0.32719945907592773, 	F1: (0, 0, 0)
[2023-02-08 12:40:11,970] INFO:__main__:==> Epoch 12, Dev 	Loss: 0.2781238257884979 	Pearson: 0.5756545066833496	MSE: 0.1828107237815857, 	F1: (0, 0, 0)
[2023-02-08 12:40:11,971] INFO:__main__:==> Epoch 12, Test 	Loss: 0.3803824484348297 	Pearson: 0.19001586735248566	MSE: 0.28294774889945984, 	F1: (0, 0, 0)
[2023-02-08 12:40:12,163] INFO:__main__:==> Epoch 13, Train 	Loss: 0.4255748689174652 	Pearson: 0.10361669212579727	MSE: 0.32719945907592773, 	F1: (0, 0, 0)
[2023-02-08 12:40:12,411] INFO:__main__:==> Epoch 13, Dev 	Loss: 0.2781238257884979 	Pearson: 0.5756545066833496	MSE: 0.1828107237815857, 	F1: (0, 0, 0)
[2023-02-08 12:40:12,412] INFO:__main__:==> Epoch 13, Test 	Loss: 0.3803824484348297 	Pearson: 0.19001586735248566	MSE: 0.28294774889945984, 	F1: (0, 0, 0)
[2023-02-08 12:40:12,695] INFO:__main__:==> Epoch 14, Train 	Loss: 0.4255748689174652 	Pearson: 0.10361669212579727	MSE: 0.32719945907592773, 	F1: (0, 0, 0)
[2023-02-08 12:40:13,000] INFO:__main__:==> Epoch 14, Dev 	Loss: 0.2781238257884979 	Pearson: 0.5756545066833496	MSE: 0.1828107237815857, 	F1: (0, 0, 0)
[2023-02-08 12:40:13,001] INFO:__main__:==> Epoch 14, Test 	Loss: 0.3803824484348297 	Pearson: 0.19001586735248566	MSE: 0.28294774889945984, 	F1: (0, 0, 0)
